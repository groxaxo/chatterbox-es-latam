# Chatterbox ES-LATAM

<div align="center">

**Sistema de SÃ­ntesis de Voz (TTS) para EspaÃ±ol Latinoamericano**

*Servidor TTS avanzado con API compatible OpenAI e interfaz web moderna*

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green.svg)](https://fastapi.tiangolo.com)
[![Docker](https://img.shields.io/badge/Docker-CUDA_12.1-blue.svg)](https://www.docker.com/)

</div>

---

## ğŸ¯ CaracterÃ­sticas

- âœ¨ **TTS de Alta Calidad**: SÃ­ntesis de voz natural optimizada para espaÃ±ol latinoamericano
- ğŸ™ï¸ **ClonaciÃ³n de Voz**: Genera audio con voces personalizadas usando muestras de referencia  
- âš¡ **Rendimiento GPU**: Soporte completo para CUDA (NVIDIA)
- ğŸŒ **API Compatible OpenAI**: Endpoint `/v1/audio/speech` compatible con OpenAI
- ğŸ¨ **Interfaz Web**: UI intuitiva en espaÃ±ol con controles avanzados
- ğŸ“ **Textos Largos**: Procesamiento inteligente con chunking automÃ¡tico

---

## ğŸš€ Quick Start

### Docker (Recomendado)

```bash
# GPU
docker-compose up -d

# CPU only
docker build --build-arg RUNTIME=cpu -t chatterbox-es-latam .
docker run -p 8004:8004 chatterbox-es-latam
```

Abre `http://localhost:8004` en tu navegador.

### InstalaciÃ³n Local

```bash
# 1. Clonar
git clone https://github.com/tu-usuario/chatterbox-es-latam.git
cd chatterbox-es-latam

# 2. Entorno virtual
python -m venv venv
source venv/bin/activate

# 3. Instalar dependencias
pip install -r requirements-nvidia.txt  # GPU
# o
pip install -r requirements.txt         # CPU

# 4. Iniciar
python server.py
```

---

## ğŸ›ï¸ Uso

### Interfaz Web

1. Abre `http://localhost:8004`
2. Escribe el texto a sintetizar
3. Selecciona una voz predefinida o sube audio de referencia
4. Ajusta parÃ¡metros y haz clic en "Generar Audio"

### API REST

#### OpenAI-Compatible

```bash
curl -X POST http://localhost:8004/v1/audio/speech \
  -H "Content-Type: application/json" \
  -d '{
    "model": "chatterbox-es-latam",
    "input": "Hola, bienvenido al sistema TTS.",
    "voice": "default.wav",
    "response_format": "mp3",
    "speed": 1.0
  }' \
  --output audio.mp3
```

#### Custom Endpoint

```bash
curl -X POST http://localhost:8004/tts \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Texto a sintetizar en espaÃ±ol latinoamericano.",
    "voice_mode": "predefined",
    "predefined_voice_id": "default.wav",
    "temperature": 0.8,
    "exaggeration": 1.0,
    "cfg_weight": 0.5,
    "speed_factor": 1.0,
    "output_format": "wav",
    "split_text": true,
    "chunk_size": 120,
    "language": "es"
  }' \
  --output audio.wav
```

---

## ğŸ“‹ API Reference

### Endpoints

| Endpoint | MÃ©todo | DescripciÃ³n |
|----------|--------|-------------|
| `/health` | GET | Health check |
| `/v1/audio/speech` | POST | Generar audio (OpenAI-compatible) |
| `/tts` | POST | Generar audio (custom) |
| `/v1/audio/voices` | GET | Listar voces disponibles |
| `/v1/voices` | GET | Alias para `/v1/audio/voices` |
| `/v1/audio/models` | GET | Listar modelos disponibles |
| `/v1/models` | GET | Alias para `/v1/audio/models` |

### ParÃ¡metros de GeneraciÃ³n

| ParÃ¡metro | Rango | Default | DescripciÃ³n |
|-----------|-------|---------|-------------|
| `temperature` | 0.0 - 1.5 | 0.8 | Aleatoriedad (menor = mÃ¡s estable) |
| `exaggeration` | 0.25 - 2.0 | 1.0 | Expresividad de la voz |
| `cfg_weight` | 0.2 - 1.0 | 0.5 | Influencia en estilo |
| `speed_factor` | 0.25 - 4.0 | 1.0 | Velocidad del audio |
| `seed` | â‰¥ 0 | 0 | Semilla para reproducibilidad |
| `split_text` | boolean | true | Dividir texto largo automÃ¡ticamente |
| `chunk_size` | 50 - 500 | 120 | TamaÃ±o de chunk para divisiÃ³n de texto |
| `language` | string | "es" | Idioma del texto |

---

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CLIENTE       â”‚         â”‚   SERVIDOR (GPU NVIDIA)        â”‚
â”‚   (Navegador)   â”‚         â”‚                                â”‚
â”‚                 â”‚  HTTP   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  EnvÃ­a texto   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  â”‚  TTS Pipeline            â”‚  â”‚
â”‚                 â”‚         â”‚  â”‚  1. Recibe texto         â”‚  â”‚
â”‚  Recibe audio  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”‚  â”‚  2. Carga modelo         â”‚  â”‚
â”‚                 â”‚  WAV    â”‚  â”‚  3. Genera audio (GPU)   â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚  â”‚  4. Retorna audio        â”‚  â”‚
                            â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Stack**:
- FastAPI (Python)
- PyTorch + Chatterbox TTS
- CUDA para GPU

---

## ğŸ’» Requisitos

### Hardware

| Componente | MÃ­nimo | Recomendado |
|------------|--------|-------------|
| GPU | RTX 3060 12GB | RTX 4090 / A100 |
| RAM | 16GB | 32GB |
| CPU | 4 cores | 8+ cores |
| Storage | 10GB | 50GB+ |

### Software

```
Docker 24.0+
NVIDIA Container Toolkit
CUDA 12.1+
Python 3.10+ (para desarrollo)
```

### Performance (RTX 4090)

| Texto | Latencia |
|-------|----------|
| Corto (~10 palabras) | ~200ms |
| Medio (~50 palabras) | ~800ms |
| Largo (~200 palabras) | ~3s |

---

## ğŸ“ Estructura

```
chatterbox-es-latam/
â”œâ”€â”€ server.py              # Servidor FastAPI principal
â”œâ”€â”€ engine.py              # Motor de inferencia
â”œâ”€â”€ config.yaml            # ConfiguraciÃ³n
â”œâ”€â”€ requirements.txt       # Dependencias CPU
â”œâ”€â”€ requirements-nvidia.txt # Dependencias GPU
â”œâ”€â”€ docker-compose.yml     # Docker Compose
â”œâ”€â”€ Dockerfile             # Docker build
â”œâ”€â”€ voices/                # Voces predefinidas
â”œâ”€â”€ reference_audio/       # Audios de referencia
â”œâ”€â”€ outputs/               # Audios generados
â”œâ”€â”€ logs/                  # Logs del servidor
â”œâ”€â”€ ui/                    # Interfaz web
â”œâ”€â”€ web/                   # React UI (desarrollo)
â””â”€â”€ training/              # Scripts de fine-tuning
```

---

## ğŸ³ Deployment

### Opciones

| OpciÃ³n | Uso | GPU | Costo |
|--------|-----|-----|-------|
| **Local/Docker** | Desarrollo | Opcional | Gratis |
| **RunPod** | ProducciÃ³n | âœ… | ~$0.20/hr |
| **AWS/GCP** | Enterprise | âœ… | Variable |

### Docker Compose

```yaml
services:
  chatterbox-tts:
    build: .
    ports:
      - "8004:8004"
    volumes:
      - ./voices:/app/voices
      - ./reference_audio:/app/reference_audio
      - ./outputs:/app/outputs
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

### RunPod

1. Crear Pod con template PyTorch + CUDA 12.1
2. GPU: RTX 3090 o superior
3. Clonar repo e instalar: `pip install -r requirements-nvidia.txt`
4. Ejecutar: `python server.py`

---

## ğŸ”’ Seguridad

- HTTPS recomendado para producciÃ³n
- Rate limiting en endpoints
- ValidaciÃ³n de inputs
- Audio temporal (no se almacena permanentemente)

---

## ğŸ™ Agradecimientos

- [Resemble AI](https://github.com/resemble-ai/chatterbox) por Chatterbox TTS

---

## ğŸ“ Licencia

MIT License
