# Chatterbox LoRA Fine-Tuning (EspaÃ±ol Rioplatense)

Este repositorio contiene todo lo necesario para realizar un fine-tuning (LoRA) del modelo **Chatterbox TTS** utilizando el dataset **Orpheus LATAM** (voces argentinas).

El objetivo es adaptar el modelo multilingÃ¼e de Resemble AI para que genere audio con acento rioplatense natural.

## ğŸ“‚ Estructura del Proyecto

```
chatterbox-es-latam/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ lora_es_latam.py    # Script principal de entrenamiento
â”‚   â”œâ”€â”€ dataset_orpheus.py  # Procesamiento del dataset Orpheus
â”‚   â””â”€â”€ test_inference.py   # Script para probar el modelo entrenado
â”œâ”€â”€ runpod_train.sh         # Script de automatizaciÃ³n para RunPod
â”œâ”€â”€ fix_pkuseg.bat          # Script de correcciÃ³n de instalaciÃ³n para Windows
â”œâ”€â”€ requirements.txt        # Dependencias del proyecto
â””â”€â”€ README.md               # Esta documentaciÃ³n
```

## ğŸš€ InstalaciÃ³n Local (Windows)

### 1. Prerrequisitos
- Python 3.10 o 3.11
- GPU NVIDIA (Recomendado: 16GB+ VRAM para training, 8GB+ para inferencia)
- [Git](https://git-scm.com/) instalado

### 2. ConfiguraciÃ³n

1.  **Clonar el repositorio:**
    ```bash
    git clone https://github.com/franclarke/chatterbox-es-latam.git
    cd chatterbox-es-latam
    ```

2.  **Crear entorno virtual:**
    ```bash
    python -m venv venv
    .\venv\Scripts\activate
    ```

3.  **Instalar dependencias (IMPORTANTE):**
    Debido a un problema de compatibilidad con la librerÃ­a `pkuseg` en Windows, debÃ©s seguir este orden exacto:

    ```cmd
    # 1. Instalar herramientas base
    pip install numpy cython setuptools wheel

    # 2. Ejecutar el script de correcciÃ³n (compila pkuseg localmente)
    fix_pkuseg.bat

    # 3. Instalar el resto de dependencias
    pip install -r requirements.txt
    ```

4.  **Login en HuggingFace:**
    Necesario para descargar el modelo base y el dataset.
    ```bash
    huggingface-cli login
    ```

## â˜ï¸ Entrenamiento en RunPod

Este repositorio estÃ¡ optimizado para correr en **RunPod** (pods con GPU NVIDIA, ej: A40, A6000, A100).

1.  **Crear Pod:** ElegÃ­ una imagen base de PyTorch (ej: `runpod/pytorch:2.1.0-py3.10-cuda11.8.0-devel-ubuntu22.04`).
2.  **Subir cÃ³digo:** PodÃ©s clonar el repo o subir los archivos directamente.
3.  **Ejecutar entrenamiento:**
    Hemos preparado un script que instala todo, arregla dependencias y lanza el entrenamiento automÃ¡ticamente.

    ```bash
    chmod +x runpod_train.sh
    ./runpod_train.sh
    ```

    *Este script guardarÃ¡ los logs en `logs/train_log.txt` para que puedas cerrar la terminal sin detener el proceso.*

## ğŸ› ï¸ Uso

### Entrenamiento (Fine-Tuning)
Para iniciar el entrenamiento manualmente:
```bash
python -m src.lora_es_latam
```
*Configuraciones como `BATCH_SIZE`, `EPOCHS`, `LEARNING_RATE` se pueden editar directamente en `src/lora_es_latam.py`.*

### Inferencia (Prueba)
Una vez finalizado el entrenamiento, se generarÃ¡ la carpeta `checkpoints_lora/merged_model`. Para probarlo:

1.  AbrÃ­ `src/test_inference.py` y editÃ¡ el texto si deseÃ¡s.
2.  EjecutÃ¡:
    ```bash
    python src/test_inference.py
    ```
3.  El audio generado se guardarÃ¡ como `test_es_ar.wav`.

## ğŸ“Š Monitoreo
Durante el entrenamiento, se genera un archivo `training_metrics.png` que se actualiza en tiempo real con grÃ¡ficos de:
- Loss (Entrenamiento y ValidaciÃ³n)
- Learning Rate
- Gradientes

## ğŸ› SoluciÃ³n de Problemas Comunes

- **Error `pkuseg` / `numpy`:** Asegurate de haber corrido `fix_pkuseg.bat` (Windows) o usar `runpod_train.sh` (Linux) que manejan la compilaciÃ³n manual de esta librerÃ­a.
- **Error `torchcodec`:** Si aparece este error, es porque `datasets` no detectÃ³ `soundfile`. Asegurate de haber instalado `requirements.txt` completo.
- **OOM (Out of Memory):** ReducÃ­ el `BATCH_SIZE` en `src/lora_es_latam.py` a 1.